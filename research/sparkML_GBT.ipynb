{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c01b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/08 11:59:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark Session started\n",
      "Spark Version: 3.5.7\n",
      "------------------------------------------------------------\n",
      "⬇️  Downloading Iris dataset...\n",
      "✅ Downloaded to /tmp/iris.csv\n",
      "Schema:\n",
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training samples: 126, Test samples: 24\n",
      "------------------------------------------------------------\n",
      "Training baseline pipeline (no hyperparam tuning)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/08 11:59:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9583\n",
      "Sample predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|   species|label|prediction|\n",
      "+----------+-----+----------+\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|versicolor|  0.0|       0.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|versicolor|  0.0|       0.0|\n",
      "+----------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------\n",
      "Starting cross-validation (this may take some time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation completed.\n",
      "------------------------------------------------------------\n",
      "Best Model summary:\n",
      "Stage 0: StringIndexer_26d39cfd3601 (StringIndexerModel)\n",
      "Stage 1: VectorAssembler_1d5ce6837e9c (VectorAssembler)\n",
      "Stage 2: StandardScaler_f7ba0702dd28 (StandardScalerModel)\n",
      "Stage 3: OneVsRestModel_746fd41be852 (OneVsRestModel)\n",
      "Cross-Validated Model Accuracy on test set: 0.9583\n",
      "Sample predictions from best model:\n",
      "+----------+-----+----------+\n",
      "|   species|label|prediction|\n",
      "+----------+-----+----------+\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|versicolor|  0.0|       0.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|    setosa|  2.0|       2.0|\n",
      "|versicolor|  0.0|       0.0|\n",
      "+----------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving best model to output/iris_gbt_onevsrest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/debabratapati/Documents/pyspark/my_pyspark_course/venv/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.5.7.jar) to field java.math.BigInteger.mag\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model successfully. Running a quick predict check...\n",
      "+-------+----------+\n",
      "|species|prediction|\n",
      "+-------+----------+\n",
      "| setosa|       2.0|\n",
      "| setosa|       2.0|\n",
      "| setosa|       2.0|\n",
      "| setosa|       2.0|\n",
      "| setosa|       2.0|\n",
      "+-------+----------+\n",
      "\n",
      "------------------------------------------------------------\n",
      "Done. Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lesson 5 (Advanced): Multiclass Gradient-Boosted Trees with One-vs-Rest (PySpark)\n",
    "=================================================================================\n",
    "\n",
    "Author: Deb\n",
    "Date: 2024-06-10\n",
    "\n",
    "Description:\n",
    "------------\n",
    "This script trains a multiclass classifier using Spark's GBTClassifier wrapped inside OneVsRest.\n",
    "It demonstrates:\n",
    " - Data ingestion (download Iris CSV)\n",
    " - Feature engineering using VectorAssembler (and optional StandardScaler)\n",
    " - StringIndexer to convert categorical labels to numeric\n",
    " - OneVsRest wrapper to extend GBT (binary) into multiclass\n",
    " - Pipeline construction\n",
    " - Hyperparameter tuning with CrossValidator\n",
    " - Model saving and loading\n",
    "\n",
    "Notes:\n",
    " - GBTClassifier in pyspark.ml is a binary classifier. Wrapping it with OneVsRest enables\n",
    "   multiclass classification by training one binary GBT per class (one-versus-rest strategy).\n",
    " - For large-scale production, consider XGBoost or LightGBM integration for true distributed GBMs.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import GBTClassifier, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Initialize Spark Session\n",
    "# ---------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"lesson5-gbt-onevsrest\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark Session started\")\n",
    "print(\"Spark Version:\", spark.version)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Download & Load Dataset\n",
    "# ---------------------------\n",
    "iris_url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
    "local_path = Path(\"/tmp/iris.csv\")\n",
    "print(\"⬇️  Downloading Iris dataset...\")\n",
    "urllib.request.urlretrieve(iris_url, str(local_path))\n",
    "print(f\"✅ Downloaded to {local_path}\")\n",
    "\n",
    "iris_df = spark.read.csv(str(local_path), header=True, inferSchema=True)\n",
    "print(\"Schema:\")\n",
    "iris_df.printSchema()\n",
    "iris_df.show(5)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Preprocessing & Features\n",
    "# ---------------------------\n",
    "# 3.1 Convert species (string) to numeric label\n",
    "label_indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
    "\n",
    "# 3.2 Assemble features into a single vector\n",
    "feature_cols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_assembled\")\n",
    "\n",
    "# 3.3 (Optional) Standard scaling - not strictly necessary for tree-based models,\n",
    "# but kept here to show the pipeline pattern and for consistency with other models.\n",
    "scaler = StandardScaler(inputCol=\"features_assembled\", outputCol=\"features\", withMean=True, withStd=True)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Define Base Binary Estimator (GBT) and One-vs-Rest wrapper\n",
    "# ---------------------------\n",
    "# GBTClassifier is binary; OneVsRest turns it into multiclass by training one binary classifier per class.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=50, maxDepth=5, stepSize=0.2)\n",
    "\n",
    "ovr = OneVsRest(classifier=gbt, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Build Pipeline\n",
    "# ---------------------------\n",
    "pipeline = Pipeline(stages=[label_indexer, assembler, scaler, ovr])\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Train/Test Split\n",
    "# ---------------------------\n",
    "train_df, test_df = iris_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Training samples: {train_df.count()}, Test samples: {test_df.count()}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Baseline fit (fast check)\n",
    "# ---------------------------\n",
    "print(\"Training baseline pipeline (no hyperparam tuning)...\")\n",
    "baseline_model = pipeline.fit(train_df)\n",
    "baseline_preds = baseline_model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "baseline_acc = evaluator.evaluate(baseline_preds)\n",
    "print(f\"Baseline Accuracy: {baseline_acc:.4f}\")\n",
    "print(\"Sample predictions:\")\n",
    "baseline_preds.select(\"species\", \"label\", \"prediction\").show(10)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Hyperparameter Tuning with CrossValidator\n",
    "# ---------------------------\n",
    "# Build a parameter grid. Because OneVsRest wraps the GBT, we reference GBT params\n",
    "# through the OneVsRest's classifier parameter path. To access nested params we use:\n",
    "#   ovr.classifier.paramName  (but ParamGridBuilder accepts the Param object from the estimator)\n",
    "#\n",
    "# We fetch the param objects directly from the gbt instance used above for clarity.\n",
    "\n",
    "param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(gbt.maxDepth, [3, 5])        # tree depth\n",
    "    .addGrid(gbt.maxIter, [20, 50])       # number of boosting iterations\n",
    "    .addGrid(gbt.stepSize, [0.1, 0.2])    # learning rate\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Note: CrossValidator internally will train OneVsRest models for each param combination.\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2  # run up to 2 models in parallel (adjust to your machine)\n",
    ")\n",
    "\n",
    "print(\"Starting cross-validation (this may take some time)...\")\n",
    "cv_model = crossval.fit(train_df)\n",
    "print(\"Cross-validation completed.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Evaluate Best Model\n",
    "# ---------------------------\n",
    "best_model = cv_model.bestModel\n",
    "print(\"Best Model summary:\")\n",
    "# It's a PipelineModel; we can inspect stages or parameters if desired\n",
    "# For brevity, show the params of the underlying GBT by traversing stages:\n",
    "for i, stage in enumerate(best_model.stages):\n",
    "    print(f\"Stage {i}: {stage.uid} ({stage.__class__.__name__})\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "cv_preds = best_model.transform(test_df)\n",
    "cv_acc = evaluator.evaluate(cv_preds)\n",
    "print(f\"Cross-Validated Model Accuracy on test set: {cv_acc:.4f}\")\n",
    "\n",
    "print(\"Sample predictions from best model:\")\n",
    "cv_preds.select(\"species\", \"label\", \"prediction\").show(10)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 10) Save & Load the Best Model\n",
    "# ---------------------------\n",
    "model_path = \"output/iris_gbt_onevsrest\"\n",
    "print(f\"Saving best model to {model_path} ...\")\n",
    "best_model.write().overwrite().save(model_path)\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Loading back (optional check)\n",
    "from pyspark.ml import PipelineModel\n",
    "loaded = PipelineModel.load(model_path)\n",
    "print(\"Loaded model successfully. Running a quick predict check...\")\n",
    "loaded_preds = loaded.transform(test_df.limit(5)).select(\"species\", \"prediction\")\n",
    "loaded_preds.show()\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 11) Cleanup\n",
    "# ---------------------------\n",
    "spark.stop()\n",
    "print(\"Done. Spark session stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.8.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
